{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5224010-2493-42c2-83f0-a2558b563053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--repeats REPEATS] [--warmups WARMUPS]\n",
      "                             [--no-check] [--out OUT] [--save-plots]\n",
      "                             [--verbose] [--wl-min WL_MIN] [--wl-max WL_MAX]\n",
      "                             [--mat-a MAT_A] [--mat-b MAT_B] [--t-a T_A]\n",
      "                             [--t-b T_B] [--wl-counts WL_COUNTS]\n",
      "                             [--layer-counts LAYER_COUNTS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/jfoley19/Library/Jupyter/runtime/kernel-eb5fe585-cb83-4e78-8c2e-745d9a29d1ad.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jfoley19/miniconda3/envs/wptherml/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import argparse\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import wptherml\n",
    "except Exception as e:\n",
    "    print(\"\\n[!] Could not import wptherml. Install it before running: pip install wptherml\\n\")\n",
    "    raise\n",
    "\n",
    "# ------------------------------\n",
    "# Helpers to build test systems\n",
    "# ------------------------------\n",
    "\n",
    "def build_stack(n_layers: int,\n",
    "                wl_count: int,\n",
    "                wl_min: float = 400e-9,\n",
    "                wl_max: float = 800e-9,\n",
    "                mat_a: str = \"SiO2\",\n",
    "                mat_b: str = \"TiO2\",\n",
    "                t_a: float = 200e-9,\n",
    "                t_b: float = 10e-9):\n",
    "    \"\"\"Construct test_args for wptherml given number of finite layers and wavelengths.\n",
    "\n",
    "    n_layers: number of finite layers (no. of thickness entries excluding the two boundary airs)\n",
    "    wl_count: number of wavelengths to sample between wl_min and wl_max (inclusive)\n",
    "    The stack alternates mat_a/mat_b starting with mat_a.\n",
    "    \"\"\"\n",
    "    if n_layers <= 0:\n",
    "        raise ValueError(\"n_layers must be >= 1\")\n",
    "    if wl_count <= 1:\n",
    "        raise ValueError(\"wl_count must be > 1\")\n",
    "\n",
    "    # Wavelength list uses the wptherml shorthand [start, end, N]\n",
    "    wavelength_list = [wl_min, wl_max, wl_count]\n",
    "\n",
    "    # Materials: Air at both ends, then alternating A/B for n_layers\n",
    "    mats = [\"Air\"]\n",
    "    thks = [0.0]\n",
    "    for i in range(n_layers):\n",
    "        if i % 2 == 0:\n",
    "            mats.append(mat_a)\n",
    "            thks.append(t_a)\n",
    "        else:\n",
    "            mats.append(mat_b)\n",
    "            thks.append(t_b)\n",
    "    mats.append(\"Air\")\n",
    "    thks.append(0.0)\n",
    "\n",
    "    test_args = {\n",
    "        \"wavelength_list\": wavelength_list,\n",
    "        \"material_list\": mats,\n",
    "        \"thickness_list\": thks,\n",
    "    }\n",
    "    return test_args\n",
    "\n",
    "\n",
    "def time_once(sf: SpectrumFactory, n_layers: int, wl_count: int, atol=1e-5, rtol=1e-5, check=True):\n",
    "    \"\"\"Time one initialization of serial and vectorized codes for the same stack.\"\"\"\n",
    "    args = build_stack(n_layers=n_layers, wl_count=wl_count)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    test_serial = sf.spectrum_factory('Tmm', args)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    t2 = time.perf_counter()\n",
    "    test_vec = sf.spectrum_factory('VecTmm', args)\n",
    "    t3 = time.perf_counter()\n",
    "\n",
    "    if check:\n",
    "        if not np.allclose(test_serial.reflectivity_array, test_vec.reflectivity_array, rtol, atol):\n",
    "            raise AssertionError(\"Serial and vectorized reflectivity arrays differ beyond tolerances.\")\n",
    "\n",
    "    return (t1 - t0), (t3 - t2)\n",
    "\n",
    "\n",
    "def benchmark_grid(sf: SpectrumFactory,\n",
    "                   wl_counts,\n",
    "                   layer_counts,\n",
    "                   repeats: int = 3,\n",
    "                   warmups: int = 1,\n",
    "                   check=True,\n",
    "                   verbose=False):\n",
    "    \"\"\"Run timing grid and return a tidy DataFrame.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    # Warmups on a moderate size to JIT/prime any caches\n",
    "    for _ in range(max(1, warmups)):\n",
    "        try:\n",
    "            time_once(sf, n_layers=max(2, layer_counts[min(1, len(layer_counts)-1)]), wl_count=max(100, wl_counts[min(1, len(wl_counts)-1)]), check=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 1) Scaling with number of wavelengths (layers fixed)\n",
    "    fixed_layers = layer_counts[-1] if len(layer_counts) > 0 else 18\n",
    "    for Nw in wl_counts:\n",
    "        times_serial = []\n",
    "        times_vec = []\n",
    "        for r in range(repeats):\n",
    "            ts, tv = time_once(sf, n_layers=fixed_layers, wl_count=Nw, check=check)\n",
    "            times_serial.append(ts)\n",
    "            times_vec.append(tv)\n",
    "            if verbose:\n",
    "                print(f\"[Î»-scale] layers={fixed_layers:2d} Nw={Nw:6d} run={r+1}/{repeats}: serial={ts:.4f}s vec={tv:.4f}s\")\n",
    "        rows.append({\"sweep\": \"wavelengths\", \"n_layers\": fixed_layers, \"n_wavelengths\": Nw,\n",
    "                     \"mode\": \"serial\", \"time_s\": float(np.median(times_serial))})\n",
    "        rows.append({\"sweep\": \"wavelengths\", \"n_layers\": fixed_layers, \"n_wavelengths\": Nw,\n",
    "                     \"mode\": \"vectorized\", \"time_s\": float(np.median(times_vec))})\n",
    "\n",
    "    # 2) Scaling with number of layers (wavelengths fixed)\n",
    "    fixed_wl = wl_counts[-1] if len(wl_counts) > 0 else 1000\n",
    "    for L in layer_counts:\n",
    "        times_serial = []\n",
    "        times_vec = []\n",
    "        for r in range(repeats):\n",
    "            ts, tv = time_once(sf, n_layers=L, wl_count=fixed_wl, check=check)\n",
    "            times_serial.append(ts)\n",
    "            times_vec.append(tv)\n",
    "            if verbose:\n",
    "                print(f\"[L-scale] layers={L:2d} Nw={fixed_wl:6d} run={r+1}/{repeats}: serial={ts:.4f}s vec={tv:.4f}s\")\n",
    "        rows.append({\"sweep\": \"layers\", \"n_layers\": L, \"n_wavelengths\": fixed_wl,\n",
    "                     \"mode\": \"serial\", \"time_s\": float(np.median(times_serial))})\n",
    "        rows.append({\"sweep\": \"layers\", \"n_layers\": L, \"n_wavelengths\": fixed_wl,\n",
    "                     \"mode\": \"vectorized\", \"time_s\": float(np.median(times_vec))})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_default_grids():\n",
    "    # Reasonable defaults. Adjust if your machine/library can handle more.\n",
    "    wl_counts = [50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 30000]\n",
    "    layer_counts = [2, 4, 6, 8, 10, 12, 16, 18, 20, 24, 30, 40]\n",
    "    return wl_counts, layer_counts\n",
    "\n",
    "\n",
    "def plot_results(df: pd.DataFrame, save_prefix: str | None = None):\n",
    "    # 1) Scaling with wavelengths\n",
    "    sub = df[df[\"sweep\"] == \"wavelengths\"].copy()\n",
    "    if not sub.empty:\n",
    "        fig1 = plt.figure()\n",
    "        for mode in [\"serial\", \"vectorized\"]:\n",
    "            d = sub[sub[\"mode\"] == mode].sort_values(\"n_wavelengths\")\n",
    "            plt.plot(d[\"n_wavelengths\"].values, d[\"time_s\"].values, marker=\"o\", label=mode)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(\"Number of wavelengths\")\n",
    "        plt.ylabel(\"Median init time (s)\")\n",
    "        layers_val = int(sub[\"n_layers\"].iloc[0]) if not sub.empty else 0\n",
    "        plt.title(f\"Initialization time vs. wavelengths (layers={layers_val})\")\n",
    "        plt.legend()\n",
    "        if save_prefix:\n",
    "            fig1.savefig(f\"{save_prefix}_vs_wavelengths.png\", dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "    # 2) Scaling with layers\n",
    "    sub = df[df[\"sweep\"] == \"layers\"].copy()\n",
    "    if not sub.empty:\n",
    "        fig2 = plt.figure()\n",
    "        for mode in [\"serial\", \"vectorized\"]:\n",
    "            d = sub[sub[\"mode\"] == mode].sort_values(\"n_layers\")\n",
    "            plt.plot(d[\"n_layers\"].values, d[\"time_s\"].values, marker=\"o\", label=mode)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(\"Number of layers (finite)\")\n",
    "        plt.ylabel(\"Median init time (s)\")\n",
    "        wl_val = int(sub[\"n_wavelengths\"].iloc[0]) if not sub.empty else 0\n",
    "        plt.title(f\"Initialization time vs. layers (Nw={wl_val})\")\n",
    "        plt.legend()\n",
    "        if save_prefix:\n",
    "            fig2.savefig(f\"{save_prefix}_vs_layers.png\", dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def summarize_speedups(df: pd.DataFrame):\n",
    "    summaries = []\n",
    "\n",
    "    for sweep in [\"wavelengths\", \"layers\"]:\n",
    "        sub = df[df[\"sweep\"] == sweep]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        # Compute speedup = serial / vectorized for each matching point\n",
    "        key = \"n_wavelengths\" if sweep == \"wavelengths\" else \"n_layers\"\n",
    "        fixed_key = \"n_layers\" if sweep == \"wavelengths\" else \"n_wavelengths\"\n",
    "        pairs = sub.groupby([key, fixed_key])\n",
    "        for (k, f), g in pairs:\n",
    "            try:\n",
    "                t_serial = g[g[\"mode\"] == \"serial\"][\"time_s\"].iloc[0]\n",
    "                t_vec = g[g[\"mode\"] == \"vectorized\"][\"time_s\"].iloc[0]\n",
    "                speedup = t_serial / t_vec if t_vec > 0 else np.nan\n",
    "                summaries.append({\"sweep\": sweep, key: k, fixed_key: f,\n",
    "                                  \"serial_s\": t_serial, \"vectorized_s\": t_vec,\n",
    "                                  \"speedup\": speedup})\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return pd.DataFrame(summaries)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Benchmark wptherml Tmm vs VecTmm initialization times.\")\n",
    "    parser.add_argument(\"--repeats\", type=int, default=3, help=\"Repeat count per grid point; median is reported\")\n",
    "    parser.add_argument(\"--warmups\", type=int, default=1, help=\"Warmups before timing\")\n",
    "    parser.add_argument(\"--no-check\", action=\"store_true\", help=\"Disable reflectivity equality check (faster)\")\n",
    "    parser.add_argument(\"--out\", type=str, default=\"tmm_timing_results.csv\", help=\"CSV output filename\")\n",
    "    parser.add_argument(\"--save-plots\", action=\"store_true\", help=\"Save PNG plots alongside CSV\")\n",
    "    parser.add_argument(\"--verbose\", action=\"store_true\")\n",
    "    parser.add_argument(\"--wl-min\", type=float, default=400e-9)\n",
    "    parser.add_argument(\"--wl-max\", type=float, default=800e-9)\n",
    "    parser.add_argument(\"--mat-a\", type=str, default=\"SiO2\")\n",
    "    parser.add_argument(\"--mat-b\", type=str, default=\"TiO2\")\n",
    "    parser.add_argument(\"--t-a\", type=float, default=200e-9)\n",
    "    parser.add_argument(\"--t-b\", type=float, default=10e-9)\n",
    "    parser.add_argument(\"--wl-counts\", type=str, default=\"50,100,200,500,1000,2000,5000,10000,20000,30000\",\n",
    "                        help=\"Comma-separated list of wavelength counts\")\n",
    "    parser.add_argument(\"--layer-counts\", type=str, default=\"2,4,6,8,10,12,16,18,20,24,30,40\",\n",
    "                        help=\"Comma-separated list of layer counts (finite layers)\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Override build_stack defaults if user changed values\n",
    "    global build_stack\n",
    "    def build_stack(n_layers: int, wl_count: int,\n",
    "                    wl_min=args.wl_min, wl_max=args.wl_max,\n",
    "                    mat_a=args.mat_a, mat_b=args.mat_b,\n",
    "                    t_a=args.t_a, t_b=args.t_b):\n",
    "        if n_layers <= 0:\n",
    "            raise ValueError(\"n_layers must be >= 1\")\n",
    "        if wl_count <= 1:\n",
    "            raise ValueError(\"wl_count must be > 1\")\n",
    "        wavelength_list = [wl_min, wl_max, wl_count]\n",
    "        mats = [\"Air\"]\n",
    "        thks = [0.0]\n",
    "        for i in range(n_layers):\n",
    "            if i % 2 == 0:\n",
    "                mats.append(mat_a)\n",
    "                thks.append(t_a)\n",
    "            else:\n",
    "                mats.append(mat_b)\n",
    "                thks.append(t_b)\n",
    "        mats.append(\"Air\")\n",
    "        thks.append(0.0)\n",
    "        return {\"wavelength_list\": wavelength_list, \"material_list\": mats, \"thickness_list\": thks}\n",
    "\n",
    "    wl_counts = [int(x) for x in args.wl_counts.split(',') if x]\n",
    "    layer_counts = [int(x) for x in args.layer_counts.split(',') if x]\n",
    "\n",
    "    sf = SpectrumFactory.SpectrumFactory()\n",
    "\n",
    "    df = benchmark_grid(sf,\n",
    "                        wl_counts=wl_counts,\n",
    "                        layer_counts=layer_counts,\n",
    "                        repeats=args.repeats,\n",
    "                        warmups=args.warmups,\n",
    "                        check=not args.no_check,\n",
    "                        verbose=args.verbose)\n",
    "\n",
    "    df.to_csv(args.out, index=False)\n",
    "    print(f\"\\nSaved results to {args.out}\")\n",
    "\n",
    "    speed = summarize_speedups(df)\n",
    "    if not speed.empty:\n",
    "        print(\"\\nSpeedups (serial / vectorized):\")\n",
    "        # Print a few key rows\n",
    "        with pd.option_context('display.max_rows', None,\n",
    "                               'display.max_columns', None,\n",
    "                               'display.width', 120):\n",
    "            print(speed.head(20))\n",
    "        speed.to_csv(args.out.replace('.csv', '_speedups.csv'), index=False)\n",
    "        print(f\"Saved speedup table to {args.out.replace('.csv', '_speedups.csv')}\")\n",
    "\n",
    "    if args.save_plots:\n",
    "        prefix = args.out.replace('.csv', '')\n",
    "        plot_results(df, save_prefix=prefix)\n",
    "        print(\"Saved plots.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26d15e-a7b7-4c4b-8844-6486d9011467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
